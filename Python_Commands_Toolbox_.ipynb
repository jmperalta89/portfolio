{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnhO18mVswlUSqZEj9wgRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmperalta89/linkedinJMPERALTA/blob/main/Python_Commands_Toolbox%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jm0Y-kCJ5zdk"
      },
      "outputs": [],
      "source": [
        "#################################\n",
        "##    PRINCIPAL LIBRARIES     ###\n",
        "#################################\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import sqlalchemy\n",
        "import urllib\n",
        "import numpy as np\n",
        "import sys\n",
        "import Scikit-learn\n",
        "import matplolib\n",
        "import seaborn\n",
        "import statsmodel\n",
        "\n",
        "#################################\n",
        "##     EXPLORE DATA           ###\n",
        "#################################\n",
        "\n",
        "# Display basic information about the DataFrame\n",
        "df.info()\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()\n",
        "\n",
        "# Get the column names\n",
        "df.columns\n",
        "\n",
        "# Get the shape of the DataFrame (rows, columns)\n",
        "df.shape\n",
        "\n",
        "# Generate summary statistics for the DataFrame\n",
        "df.describe()\n",
        "\n",
        "# Get data types of columns\n",
        "df.dtypes()\n",
        "\n",
        "# Count the occurrences of each value in a specific column\n",
        "df[\"Dimension\"].value_counts()\n",
        "\n",
        "# Calculate quantiles for the DataFrame\n",
        "df.quantile([0.25, 0.75])\n",
        "\n",
        "# Count non-null values for each column\n",
        "df.count()\n",
        "\n",
        "# Count the number of null values in each column\n",
        "df.isnull().sum()\n",
        "\n",
        "# Get the total number of elements (cells) in the DataFrame\n",
        "df.size()\n",
        "\n",
        "#################################\n",
        "##     DATA WRANGLING         ##\n",
        "#################################\n",
        "\n",
        "# Slice string values in a column\n",
        "df[\"column\"] = df.column.str.slice(0, 11)\n",
        "\n",
        "# Select all rows in df where a specific column matches values in df2\n",
        "df[df.Dimention.isin(df2.Dimention)]\n",
        "\n",
        "# Drop columns that are not needed\n",
        "df = df.drop(columns=[\"xxx\"])\n",
        "\n",
        "# Convert data type of a column to string\n",
        "df[\"dimention\"] = df.dimention.astype(str)\n",
        "\n",
        "# Reorder columns according to a specified list\n",
        "New_order = ['---']\n",
        "df = df.reindex(columns=New_order)\n",
        "\n",
        "# Generate a new DataFrame by filtering values in an existing DataFrame\n",
        "df2 = df[df.dimention == '09']\n",
        "\n",
        "# Compute and append a new column using existing columns\n",
        "df.assign(AREA=lambda df: df.Length * df.Height)\n",
        "\n",
        "# Remove trailing whitespace from a column of strings\n",
        "df[\"ID\"] = df.ID.str.rstrip()\n",
        "\n",
        "# Remove duplicate rows based on a specific column\n",
        "df = df.drop_duplicates(subset=[\"column\"])\n",
        "\n",
        "# Add a new empty column to the DataFrame\n",
        "df[\"dimention\"] = \"\"\n",
        "\n",
        "# Set a constant value in a column\n",
        "df[\"dimention\"] = \"2\"\n",
        "\n",
        "# Remove rows with null values in a specific column\n",
        "df = df.dropna(subset=[\"Dimension\"])\n",
        "\n",
        "# Check if a column matches a specific value and create a boolean Series\n",
        "df = df[\"Quality\"] == 5\n",
        "\n",
        "# Delete multiple columns\n",
        "df = df.drop(columns=[\"Col\", \"Col2\"])\n",
        "\n",
        "# Rename a column\n",
        "df = df.rename(columns={\"col1\": \"New_name\"})\n",
        "\n",
        "# Melt the DataFrame to gather columns into rows\n",
        "pd.melt(df)\n",
        "\n",
        "# Concatenate two DataFrames\n",
        "df = df2.append(df)\n",
        "\n",
        "# Pivot the DataFrame based on specific columns\n",
        "df.pivot(columns='var', values='val')\n",
        "\n",
        "# Sort the DataFrame by a column in ascending order\n",
        "df.sort_values('dimention')\n",
        "\n",
        "# Sort the DataFrame by a column in descending order\n",
        "df.sort_values('dimention', ascending=False)\n",
        "\n",
        "# Filter rows based on a logical condition\n",
        "df[df.Length > 7]\n",
        "\n",
        "# Randomly select a specified number of rows\n",
        "df.sample(n=10)\n",
        "\n",
        "# Multiply values in a column by a constant\n",
        "df['Unit_price'] *= 1.03\n",
        "\n",
        "# Select values using NumPy conditions\n",
        "a = np.array([1, 2, 3, 4, 5, 6])\n",
        "a[a >= 2]\n",
        "\n",
        "# Identify values that meet a logical criteria (True/False)\n",
        "N = N > 10\n",
        "\n",
        "# Display the actual values that meet the criteria\n",
        "N[N > 10]\n",
        "\n",
        "# Identify null values in the DataFrame\n",
        "df.isnull()\n",
        "df.isna()\n",
        "\n",
        "# Drop rows with any column containing null data\n",
        "df.dropna()\n",
        "\n",
        "# Replace all null (NA) values with a specific value (e.g., 0)\n",
        "df.fillna(0)\n",
        "\n",
        "# Count the number of null values in each column\n",
        "df.isnull().sum()\n",
        "df.isna().count()\n",
        "\n",
        "# Drop all rows with at least one null value\n",
        "df.dropna()\n",
        "\n",
        "# Drop columns with all null values\n",
        "df.dropna(how='all', axis='columns')\n",
        "\n",
        "# Find unique values in a column\n",
        "df['DIMENTION'].unique()\n",
        "\n",
        "# Count the number of distinct values in a column\n",
        "df[\"Dimention\"].nunique()\n",
        "\n",
        "# Replace values in a column\n",
        "df['DIMENTION'].replace('M', 'F')\n",
        "\n",
        "# Replace multiple values in a column\n",
        "df['DIMENTION'].replace({'M': 'F', 'D': 'F'})\n",
        "\n",
        "# Identify and drop duplicated rows\n",
        "df.duplicated()\n",
        "df.drop_duplicates(keep=False, subset='DIMENTION')\n",
        "\n",
        "# Split a string column into multiple columns using a delimiter\n",
        "df['DIMENTION_STRINGS'].str.split('-', expand=True)\n",
        "\n",
        "# Check if a string column contains a specific character or substring\n",
        "df['DIMENTION_STRINGS'].str.contains('-')\n",
        "\n",
        "# Replace values in a string column\n",
        "df['DIMENTION_STRINGS'].str.replace()\n",
        "\n",
        "# Round a floating-point number to two decimal places\n",
        "df.round(2)\n",
        "\n",
        "# Select multiple columns by their names\n",
        "df[['width', 'length', 'species']]\n",
        "\n",
        "\n",
        "############# Use LOC and ILOC for data selection (loc by label, iloc by integer location)#######\n",
        "\n",
        "# Select a specific cell by row position and column position\n",
        "df.iloc[0, 2]\n",
        "\n",
        "# Select specific columns by their integer positions\n",
        "df.iloc[:, [1, 2, 5]]\n",
        "\n",
        "# Select the last row\n",
        "df.iloc[-1]\n",
        "\n",
        "# Select a range of rows and columns by label\n",
        "df.loc['Canada':'Italy', 'Population':'GDP']\n",
        "\n",
        "# Search for a specific value in a column\n",
        "df.loc[df['customer_last_name'] == 'Smith']\n",
        "\n",
        "#################\n",
        "# DATA SOURCES  #\n",
        "#################\n",
        "\n",
        "# Using an Excel file as a data source\n",
        "excelfile = pd.read_excel('your_file.xlsx')\n",
        "\n",
        "# Using a JSON file as a data source\n",
        "jsonfile = pd.read_json('your_file.json')\n",
        "\n",
        "# Using a web page table as a data source\n",
        "url = 'https://example.com/table.html'\n",
        "webdata = pd.read_html(url)[0]  # Adjust index based on the table position\n",
        "\n",
        "# Using a CSV file as a data source\n",
        "csvfile = pd.read_csv('your_file.csv')\n",
        "\n",
        "# Using a text (TXT) file as a data source\n",
        "txtfile = pd.read_csv('your_file.txt', delimiter='\\t')\n",
        "\n",
        "#################################\n",
        "##       CONDITIONALS          ##\n",
        "#################################\n",
        "\n",
        "# Conditional statement using NumPy's np.where\n",
        "# If 'Dimension' is 'F4', set the column 'Nombre_columna' to \"True,\" otherwise \"False\"\n",
        "df.loc[:, 'column'] = np.where((df.Dimention == 'F4'), \"True\", \"False\")\n",
        "\n",
        "# Conditional statement with a fallback option from df2\n",
        "# If 'Dimension' is 'F4', set the column 'Nombre_columna' to \"True,\"\n",
        "# otherwise, use the corresponding value from df2\n",
        "df.loc[:, 'column'] = np.where((df.Dimention == 'F4'), \"True\", df2.loc[:, 'column'])\n",
        "\n",
        "# Applying a custom function to create a new column based on conditions\n",
        "def categorize_value(x):\n",
        "    if x > 10:\n",
        "        return 'High'\n",
        "    elif x > 5:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'Low'\n",
        "\n",
        "df['Category'] = np.vectorize(categorize_value)(df['Value'])\n",
        "\n",
        "# Using multiple conditions with different outcomes\n",
        "df['Result'] = np.where((df['Condition1'] > 0) & (df['Condition2'] == 'A'), 'CategoryA', 'CategoryB')\n",
        "\n",
        "# Using a list comprehension to create a new list based on a condition\n",
        "original_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Squaring each element if it's even, otherwise keeping the original value\n",
        "new_list = [x**2 if x % 2 == 0 else x for x in original_list]\n",
        "\n",
        "#################################\n",
        "##   DATA MERGING              ##\n",
        "#################################\n",
        "\n",
        "# Merge two DataFrames (SQL-style) with a left join on specified columns\n",
        "df = pd.merge(sql, sql2, how=\"left\", on=[\"ID\", \"Name\"])\n",
        "\n",
        "#################################\n",
        "##      GROUP BY              ##\n",
        "#################################\n",
        "\n",
        "# Group the DataFrame by a specific column\n",
        "df.groupby(by=\"Dimention\")\n",
        "\n",
        "# Return a groupby object with values grouped by an index level named 'IND'\n",
        "df.groupby(level=\"IND\")\n",
        "\n",
        "# Group by 'Month' and count the occurrences of 'Type', then reset the index\n",
        "df.groupby([\"Month\"])[\"Type\"].count().reset_index()\n",
        "\n",
        "# Get the size of each group when grouped by 'Region'\n",
        "df.groupby('Region').size()\n",
        "\n",
        "#################################\n",
        "##       FUNCTIONS            ##\n",
        "#################################\n",
        "\n",
        "# Apply a function to each element of the DataFrame\n",
        "df.apply(function)\n",
        "\n",
        "# Define a function to filter a DataFrame\n",
        "def filter_df(df, column_name, value):\n",
        "    return df[df[column_name] != value]\n",
        "\n",
        "# Remove single quotes from all elements in the DataFrame\n",
        "df_csv = df_csv.applymap(lambda x: x.replace(\"'\", ''))\n",
        "\n",
        "# Use a lambda function to convert 'Edad_Nexos' from days to years\n",
        "df['age'] = df['days'].apply(lambda x: x.days / 365)\n",
        "\n",
        "\n",
        "#################################\n",
        "##    EXPORTING FILES         ##\n",
        "#################################\n",
        "\n",
        "# Export the DataFrame to an Excel file\n",
        "df.to_excel(\"df.xlsx\")\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "df.to_csv(\"df.csv\")\n",
        "\n",
        "# Export the DataFrame to a JSON file\n",
        "df.to_json(\"df.json\", orient='records')\n",
        "\n",
        "# Export the DataFrame to a Parquet file\n",
        "df.to_parquet(\"df.parquet\")"
      ]
    }
  ]
}